{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ganmnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stpraha/DCGAN/blob/master/ganmnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pFBrdZrlHavd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "data = np.array(np.random.randint(0,255,5*64*64*3).reshape(5,64*64*3))\n",
        "print(data)\n",
        "x_mean = data.mean(axis = 0)\n",
        "x_var = data.var(axis = 0)\n",
        "x_max = data.max(axis = 0)\n",
        "x_min = data.min(axis = 0)\n",
        "print(x_max)\n",
        "print(x_min)\n",
        "\n",
        "minmax = MinMaxScaler()\n",
        "data1 = minmax.fit_transform(data)\n",
        "print(data1)\n",
        "\n",
        "data3 = x_max - x_min\n",
        "print(data3)\n",
        "data2 = data - x_min\n",
        "print(data2)\n",
        "print(data2/data3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqvQKczs7LWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Sep  7 16:42:44 2018\n",
        "\n",
        "@author: Administrator\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "#import basic_nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "print(tf.__version__)\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "# 定义参数\n",
        "batch_size = 64\n",
        "noise_size = 100\n",
        "epochs = 800\n",
        "sample_num = 16\n",
        "learning_rate = 0.001\n",
        "d_learning_rate = 0.00005\n",
        "g_learning_rate = 0.0002\n",
        "beta1 = 0.4\n",
        "keep_prob = 0.8\n",
        "dataset_path = 'drive//cat_train_64_total.tfrecords'\n",
        "save_path = 'drive//ganpic1'\n",
        "\n",
        "\n",
        "def load_cat_record():\n",
        "    path=dataset_path\n",
        "    filename_queue = tf.train.string_input_producer([path]) #读入流中\n",
        "    reader = tf.TFRecordReader()\n",
        "    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "                                       features={\n",
        "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
        "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
        "                                       })  #取出包含image和label的feature对象\n",
        "    image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
        "    image = tf.reshape(image, [64, 64, 3])\n",
        "    label = tf.cast(features['label'], tf.int32)    \n",
        "    train_img = []\n",
        "    with tf.Session() as sess: #开始一个会话\n",
        "        init_op = tf.initialize_all_variables()\n",
        "        sess.run(init_op)\n",
        "        coord=tf.train.Coordinator()\n",
        "        threads= tf.train.start_queue_runners(coord=coord)\n",
        "        for i in range(9416):\n",
        "            example, l = sess.run([image,label])#在会话中取出image和label\n",
        "            train_img.append(example)\n",
        "        coord.request_stop()\n",
        "        coord.join(threads)\n",
        "        \n",
        "        #以下将image进行标准化\n",
        "        #在colab上可以用sklearn，但在自己电脑上sklearn出毛病了，所以改掉了。\n",
        "        images = np.array(train_img, dtype = 'float32')\n",
        "        print(images.shape)\n",
        "        x_train_row = images.reshape(images.shape[0], 64 * 64 * 3)\n",
        "        x_max_row = x_train_row.max(axis = 0)\n",
        "        x_min_row = x_train_row.min(axis = 0)\n",
        "        x_normal = (x_train_row - x_min_row) / (x_max_row - x_min_row)\n",
        "        # 重新变为64 x 64 x 3\n",
        "        images = x_normal.reshape(x_normal.shape[0], 64, 64, 3)\n",
        "        print(images.shape)\n",
        "    return images\n",
        "\n",
        "def generator(noise_img, output_dim, is_train = True, keep_prob = keep_prob):\n",
        "    with tf.variable_scope(\"generator\", reuse = tf.AUTO_REUSE):\n",
        "\t    #4 * 4 * 512\n",
        "        layer1 = tf.layers.dense(noise_img, 4 * 4 * 1024)\n",
        "        layer1 = tf.reshape(layer1, [-1, 4, 4, 1024])\n",
        "        #layer1 = tf.layers.batch_normalization(layer1, training = is_train)\n",
        "        layer1 = tf.nn.selu(layer1)\n",
        "        layer1 = tf.nn.dropout(layer1, keep_prob = keep_prob)\n",
        "        \n",
        "        # 4 * 4 * 1024 to 8 * 8 * 512\n",
        "        layer2 = tf.layers.conv2d_transpose(layer1, 512, 3, strides = 2, padding = 'same')\n",
        "        #layer2 = tf.layers.batch_normalization(layer2, training = is_train)\n",
        "        layer2 = tf.nn.selu(layer2)\n",
        "        layer2 = tf.nn.dropout(layer2, keep_prob = keep_prob)\n",
        "        \n",
        "        # tf.layers.conv2d_transpose 反卷积；strides：理解成放大倍数；\n",
        "        # 256 filters, 输出卷积核的数量； 3 kernel_size, 在卷积操作中卷积核的大小；\n",
        "        # 8 * 8 * 512 to 16 * 16 * 256\n",
        "        layer3 = tf.layers.conv2d_transpose(layer2, 256, 4, strides = 2, padding = 'same')\n",
        "        #layer3 = tf.layers.batch_normalization(layer3, training = is_train)\n",
        "        layer3 = tf.nn.selu(layer3)\n",
        "        layer3 = tf.nn.dropout(layer3, keep_prob = keep_prob)\n",
        "        \n",
        "        # 16 * 16 * 256 to 32 * 32 * 128\n",
        "        layer4 = tf.layers.conv2d_transpose(layer3, 128, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = is_train)\n",
        "        layer4 = tf.nn.selu(layer4)\n",
        "        layer4 = tf.nn.dropout(layer4, keep_prob = keep_prob)\n",
        "        \n",
        "        #to 64 * 64 * 3\n",
        "        logits = tf.layers.conv2d_transpose(layer4, output_dim, 3, strides = 2, padding = 'same')\n",
        "        output = tf.tanh(logits)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "def discriminator(input_img, keep_prob = keep_prob):\n",
        "\n",
        "    with tf.variable_scope(\"discriminator\", reuse = tf.AUTO_REUSE):\n",
        "        #64 * 64 * 3 to 32 * 32 * 128\n",
        "        layer1 = tf.layers.conv2d(input_img, 128, 3, strides = 2, padding = 'same')\n",
        "        layer1 = tf.nn.selu(layer1)\n",
        "        layer1 = tf.nn.dropout(layer1, keep_prob = keep_prob)\n",
        "    \n",
        "        # 32 * 32 * 128 to 16 * 16 * 256\n",
        "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides = 2, padding = 'same')\n",
        "        #layer2 = tf.layers.batch_normalization(layer2, training = True)\n",
        "        layer2 = tf.nn.selu(layer2)\n",
        "        layer2 = tf.nn.dropout(layer2, keep_prob = keep_prob)\n",
        "        \n",
        "        #16 * 16 * 256 to 8 * 8 * 512\n",
        "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides = 2, padding = 'same')\n",
        "        #layer3 = tf.layers.batch_normalization(layer3, training = True)\n",
        "        layer3 = tf.nn.selu(layer3)\n",
        "        layer3 = tf.nn.dropout(layer3, keep_prob = keep_prob)\n",
        "        \n",
        "        #8 * 8 * 512 to 4 * 4 * 1024\n",
        "        layer4 = tf.layers.conv2d(layer3, 1024, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = True)\n",
        "        layer4 = tf.nn.selu(layer4)\n",
        "        layer4 = tf.nn.dropout(layer4, keep_prob = keep_prob)\n",
        "        \n",
        "        \n",
        "        #4 * 4 * 1024 to 4 * 4 * 1024 * 1\n",
        "        flatten = tf.reshape(layer4, (-1, 4*4*1024))\n",
        "        logits = tf.layers.dense(flatten, 1)\n",
        "        output = tf.sigmoid(logits)\n",
        "    \n",
        "        return logits, output\n",
        "\n",
        "def loss(input_real, input_noise, image_depth):\n",
        "\n",
        "    g_output = generator(input_noise, image_depth, is_train=True)\n",
        "\t\n",
        "    d_logits_real, d_output_real = discriminator(input_real)\n",
        "    d_logits_fake, d_output_fake = discriminator(g_output)#, reuse=True)\n",
        "    \n",
        "    #计算loss\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_fake, labels = tf.ones_like(d_output_fake) * 0.9))#加上了smooth\n",
        "\t\n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_real, labels = tf.ones_like(d_output_real) * 0.9))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_fake, labels = tf.zeros_like(d_output_fake)))\n",
        "\t\n",
        "    d_loss = tf.add(d_loss_real, d_loss_fake)\n",
        "    \n",
        "    return g_loss, d_loss\n",
        "\n",
        "def optimizer(g_loss, d_loss, g_learning_rate = g_learning_rate, d_learning_rate = d_learning_rate):\n",
        "    train_vars = tf.trainable_variables()\n",
        "    \n",
        "    g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
        "    \n",
        "    #Optimizer\n",
        "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        g_opt = tf.train.AdamOptimizer(g_learning_rate).minimize(g_loss, var_list=g_vars)\n",
        "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(d_loss, var_list=d_vars)\n",
        "        \n",
        "    return g_opt, d_opt    \n",
        "    \n",
        "def show_image(sess, input_noise, data_shape, epoch, sample_num = sample_num):\n",
        "\tnoise_shape = input_noise.get_shape().as_list()[-1]\n",
        "\tsample_noise = get_noise(sample_num, noise_size)\n",
        "\tsamples = sess.run(generator(input_noise, data_shape[-1], keep_prob = 1), feed_dict = {input_noise: sample_noise})\n",
        "\tsamples = (samples + 1) / 2\n",
        "\tfig = plt.figure(figsize = (12, 12))\n",
        "\tgs = gridspec.GridSpec(4, 4)\n",
        "\tfor i, sample in enumerate(samples):\n",
        "\t\tax = plt.subplot(gs[i])\n",
        "\t\t#ax.set_xticklabels([])\n",
        "\t\tax.set_aspect('equal')\n",
        "\t\tax.get_xaxis().set_visible(False)\n",
        "\t\tax.get_yaxis().set_visible(False)\n",
        "\t\tplt.imshow(sample.reshape(data_shape[1], data_shape[2], data_shape[3]), cmap = 'Greys_r')\t\n",
        "\tplt.savefig(save_path + '//{}.png'.format(str(epoch).zfill(4)), bbox_inches='tight')\n",
        "\t#i += 1\n",
        "\tplt.close(fig)\n",
        "\t\n",
        "def get_input(img_width, img_height, img_depth, noise_size):\n",
        "\tinput_real = tf.placeholder(tf.float32, [None, img_width, img_height, img_depth], name = 'input_real')\n",
        "\tinput_noise = tf.placeholder(tf.float32, [None, noise_size], name = 'input_noise')\n",
        "\treturn input_real, input_noise\n",
        "\n",
        "\n",
        "def get_noise(batch_size, noise_size):\n",
        "\tnoise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
        "\treturn noise\n",
        "\t\n",
        "def train(noise_size, data_shape, batch_size):\n",
        "\tinput_real, input_noise = get_input(data_shape[1], data_shape[2], data_shape[3], noise_size)\n",
        "\tg_loss, d_loss = loss(input_real, input_noise, data_shape[-1])\n",
        "\tg_opt, d_opt = optimizer(g_loss, d_loss, d_learning_rate = d_learning_rate, g_learning_rate = g_learning_rate)\n",
        "\t\n",
        "\twith tf.Session() as sess:\n",
        "\t\tsess.run(tf.global_variables_initializer())\n",
        "\t\tfor i in range(epochs):\n",
        "\t\t\tfor j in range(images.shape[0]//batch_size - 1):\n",
        "\t\t\t\tbatch_image = images[j * batch_size : (j + 1) * batch_size]\n",
        "\t\t\t\tbatch_image = batch_image * 2 - 1\n",
        "\t\t\t\tbatch_noise = get_noise(batch_size, noise_size)\n",
        "\t\t\t\t\n",
        "\t\t\t\tsess.run(g_opt, feed_dict = {input_real: batch_image, input_noise: batch_noise})\n",
        "\t\t\t\tsess.run(d_opt, feed_dict = {input_real: batch_image, input_noise: batch_noise})\n",
        "                        \n",
        "\t\t\t#显示图片\n",
        "\t\t\tprint('round :', i)\n",
        "\t\t\tprint('G loss: ', g_loss.eval({input_real: batch_image, input_noise: batch_noise}))\n",
        "\t\t\tprint('D loss: ', d_loss.eval({input_real: batch_image, input_noise: batch_noise}))\n",
        "\t\t\tprint('')\n",
        "\t\t\tshow_image(sess, input_noise, data_shape, epoch = i)\n",
        "\t\t\t\t\n",
        "with tf.Graph().as_default():\n",
        "    images = load_cat_record()\n",
        "    train(noise_size, [-1, 64, 64, 3], batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io0U0F3YIaMS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Sep  7 16:42:44 2018\n",
        "\n",
        "@author: Administrator\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "#import basic_nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "# 定义参数\n",
        "batch_size = 64\n",
        "noise_size = 100\n",
        "epochs = 800\n",
        "sample_num = 16\n",
        "learning_rate = 0.001\n",
        "d_learning_rate = 0.00005\n",
        "g_learning_rate = 0.0002\n",
        "beta1 = 0.4\n",
        "keep_prob = 0.8\n",
        "dataset_path = 'drive//cat_train_128_total.tfrecords'\n",
        "save_path = 'drive//ganpic2'\n",
        "\n",
        "\n",
        "def load_cat_record():\n",
        "    path=dataset_path\n",
        " \n",
        "    filename_queue = tf.train.string_input_producer([path]) #读入流中\n",
        "    reader = tf.TFRecordReader()\n",
        "    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "                                       features={\n",
        "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
        "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
        "                                       })  #取出包含image和label的feature对象\n",
        "    image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
        "    image = tf.reshape(image, [128, 128, 3])\n",
        "    label = tf.cast(features['label'], tf.int32)\n",
        "    \n",
        "    train_img = []\n",
        "    with tf.Session() as sess: #开始一个会话\n",
        "        init_op = tf.initialize_all_variables()\n",
        "        sess.run(init_op)\n",
        "        coord=tf.train.Coordinator()\n",
        "        threads= tf.train.start_queue_runners(coord=coord)\n",
        "        for i in range(9416):\n",
        "            example, l = sess.run([image,label])#在会话中取出image和label\n",
        "            train_img.append(example)\n",
        "        coord.request_stop()\n",
        "        coord.join(threads)\n",
        "    return train_img\n",
        "\n",
        "image = load_cat_record()\n",
        "print(len(image))\n",
        "image = np.array(image, dtype = 'float32')\n",
        "print(image.shape)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler()\n",
        "# 重塑\n",
        "x_train_rows = image.reshape(image.shape[0], 128 * 128 * 3)\n",
        "print(x_train_rows.shape)\n",
        "# 归一化\n",
        "x_train = minmax.fit_transform(x_train_rows)\n",
        "# 重新变为64 x 64 x 3\n",
        "images = x_train.reshape(x_train.shape[0], 128, 128, 3)\n",
        "print(image.shape)\n",
        "\n",
        "\n",
        "\n",
        "def generator(noise_img, output_dim, is_train = True, keep_prob = keep_prob):\n",
        "    with tf.variable_scope(\"generator\", reuse = tf.AUTO_REUSE):\n",
        "\t    #4 * 4 * 512\n",
        "        layer1 = tf.layers.dense(noise_img, 4 * 4 * 2048)\n",
        "        layer1 = tf.reshape(layer1, [-1, 4, 4, 2048])\n",
        "        #layer1 = tf.layers.batch_normalization(layer1, training = is_train)\n",
        "        layer1 = tf.nn.selu(layer1)\n",
        "        layer1 = tf.nn.dropout(layer1, keep_prob = keep_prob)\n",
        "        \n",
        "        # 4 * 4 * 1024 to 8 * 8 * 512\n",
        "        layer2 = tf.layers.conv2d_transpose(layer1, 1024, 3, strides = 2, padding = 'same')\n",
        "        #layer2 = tf.layers.batch_normalization(layer2, training = is_train)\n",
        "        layer2 = tf.nn.selu(layer2)\n",
        "        layer2 = tf.nn.dropout(layer2, keep_prob = keep_prob)\n",
        "        \n",
        "        # tf.layers.conv2d_transpose 反卷积；strides：理解成放大倍数；\n",
        "        # 256 filters, 输出卷积核的数量； 3 kernel_size, 在卷积操作中卷积核的大小；\n",
        "        # 8 * 8 * 512 to 16 * 16 * 256\n",
        "        layer3 = tf.layers.conv2d_transpose(layer2, 512, 4, strides = 2, padding = 'same')\n",
        "        #layer3 = tf.layers.batch_normalization(layer3, training = is_train)\n",
        "        layer3 = tf.nn.selu(layer3)\n",
        "        layer3 = tf.nn.dropout(layer3, keep_prob = keep_prob)\n",
        "        \n",
        "        # 16 * 16 * 256 to 32 * 32 * 128\n",
        "        layer4 = tf.layers.conv2d_transpose(layer3, 256, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = is_train)\n",
        "        layer4 = tf.nn.selu(layer4)\n",
        "        layer4 = tf.nn.dropout(layer4, keep_prob = keep_prob)\n",
        "        \n",
        "        # 16 * 16 * 256 to 32 * 32 * 128\n",
        "        layer5 = tf.layers.conv2d_transpose(layer4, 128, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = is_train)\n",
        "        layer5 = tf.nn.selu(layer5)\n",
        "        layer5 = tf.nn.dropout(layer5, keep_prob = keep_prob)\n",
        "        \n",
        "        #to 64 * 64 * 3\n",
        "        logits = tf.layers.conv2d_transpose(layer5, output_dim, 3, strides = 2, padding = 'same')\n",
        "        output = tf.tanh(logits)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "\n",
        "def discriminator(input_img, keep_prob = keep_prob):\n",
        "\n",
        "    with tf.variable_scope(\"discriminator\", reuse = tf.AUTO_REUSE):\n",
        "        #64 * 64 * 3 to 32 * 32 * 128\n",
        "        layer1 = tf.layers.conv2d(input_img, 128, 3, strides = 2, padding = 'same')\n",
        "        layer1 = tf.nn.selu(layer1)\n",
        "        layer1 = tf.nn.dropout(layer1, keep_prob = keep_prob)\n",
        "    \n",
        "        # 32 * 32 * 128 to 16 * 16 * 256\n",
        "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides = 2, padding = 'same')\n",
        "        #layer2 = tf.layers.batch_normalization(layer2, training = True)\n",
        "        layer2 = tf.nn.selu(layer2)\n",
        "        layer2 = tf.nn.dropout(layer2, keep_prob = keep_prob)\n",
        "        \n",
        "        #16 * 16 * 256 to 8 * 8 * 512\n",
        "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides = 2, padding = 'same')\n",
        "        #layer3 = tf.layers.batch_normalization(layer3, training = True)\n",
        "        layer3 = tf.nn.selu(layer3)\n",
        "        layer3 = tf.nn.dropout(layer3, keep_prob = keep_prob)\n",
        "        \n",
        "        #8 * 8 * 512 to 4 * 4 * 1024\n",
        "        layer4 = tf.layers.conv2d(layer3, 1024, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = True)\n",
        "        layer4 = tf.nn.selu(layer4)\n",
        "        layer4 = tf.nn.dropout(layer4, keep_prob = keep_prob)\n",
        "        \n",
        "        #8 * 8 * 512 to 4 * 4 * 1024\n",
        "        layer5 = tf.layers.conv2d(layer4, 2048, 3, strides = 2, padding = 'same')\n",
        "        #layer4 = tf.layers.batch_normalization(layer4, training = True)\n",
        "        layer5 = tf.nn.selu(layer4)\n",
        "        layer5 = tf.nn.dropout(layer4, keep_prob = keep_prob)\n",
        "        \n",
        "        #4 * 4 * 1024 to 4 * 4 * 1024 * 1\n",
        "        flatten = tf.reshape(layer5, (-1, 4*4*2048))\n",
        "        logits = tf.layers.dense(flatten, 1)\n",
        "        output = tf.sigmoid(logits)\n",
        "    \n",
        "        return logits, output\n",
        "\n",
        "def loss(input_real, input_noise, image_depth):\n",
        "\n",
        "    g_output = generator(input_noise, image_depth, is_train=True)\n",
        "\t\n",
        "    d_logits_real, d_output_real = discriminator(input_real)\n",
        "    d_logits_fake, d_output_fake = discriminator(g_output)#, reuse=True)\n",
        "    \n",
        "    #计算loss\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_fake, labels = tf.ones_like(d_output_fake) * 0.9))\n",
        "\t\n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_real, labels = tf.ones_like(d_output_real) * 0.9))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logits_fake, labels = tf.zeros_like(d_output_fake)))\n",
        "\t\n",
        "    d_loss = tf.add(d_loss_real, d_loss_fake)\n",
        "    \n",
        "    return g_loss, d_loss\n",
        "\n",
        "def optimizer(g_loss, d_loss, g_learning_rate = g_learning_rate, d_learning_rate = d_learning_rate):\n",
        "    train_vars = tf.trainable_variables()\n",
        "    \n",
        "    g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
        "    \n",
        "    #Optimizer\n",
        "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        g_opt = tf.train.AdamOptimizer(g_learning_rate).minimize(g_loss, var_list=g_vars)\n",
        "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(d_loss, var_list=d_vars)\n",
        "        \n",
        "    return g_opt, d_opt    \n",
        "    \n",
        "def show_image(sess, input_noise, data_shape, epoch, sample_num = sample_num):\n",
        "\tnoise_shape = input_noise.get_shape().as_list()[-1]\n",
        "\tsample_noise = get_noise(sample_num, noise_size)\n",
        "\tsamples = sess.run(generator(input_noise, data_shape[-1], keep_prob = 1), feed_dict = {input_noise: sample_noise})\n",
        "\tsamples = (samples + 1) / 2\n",
        "\tfig = plt.figure(figsize = (12, 12))\n",
        "\tgs = gridspec.GridSpec(4, 4)\n",
        "\tfor i, sample in enumerate(samples):\n",
        "\t\tax = plt.subplot(gs[i])\n",
        "\t\t#ax.set_xticklabels([])\n",
        "\t\tax.set_aspect('equal')\n",
        "\t\tax.get_xaxis().set_visible(False)\n",
        "\t\tax.get_yaxis().set_visible(False)\n",
        "\t\tplt.imshow(sample.reshape(data_shape[1], data_shape[2], data_shape[3]), cmap = 'Greys_r')\t\n",
        "\tplt.savefig(save_path + '//{}.png'.format(str(epoch).zfill(4)), bbox_inches='tight')\n",
        "\t#i += 1\n",
        "\tplt.close(fig)\n",
        "\t\n",
        "def get_input(img_width, img_height, img_depth, noise_size):\n",
        "\tinput_real = tf.placeholder(tf.float32, [None, img_width, img_height, img_depth], name = 'input_real')\n",
        "\tinput_noise = tf.placeholder(tf.float32, [None, noise_size], name = 'input_noise')\n",
        "\treturn input_real, input_noise\n",
        "\n",
        "\n",
        "def get_noise(batch_size, noise_size):\n",
        "\tnoise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
        "\treturn noise\n",
        "\t\n",
        "def train(noise_size, data_shape, batch_size):\n",
        "\tinput_real, input_noise = get_input(data_shape[1], data_shape[2], data_shape[3], noise_size)\n",
        "\tg_loss, d_loss = loss(input_real, input_noise, data_shape[-1])\n",
        "\tg_opt, d_opt = optimizer(g_loss, d_loss, d_learning_rate = d_learning_rate, g_learning_rate = g_learning_rate)\n",
        "\t\n",
        "\twith tf.Session() as sess:\n",
        "\t\tsess.run(tf.global_variables_initializer())\n",
        "\t\tfor i in range(epochs):\n",
        "\t\t\tfor j in range(images.shape[0]//batch_size - 1):\n",
        "\t\t\t\tbatch_image = images[j * batch_size : (j + 1) * batch_size]\n",
        "\t\t\t\tbatch_image = batch_image * 2 - 1\n",
        "\t\t\t\tbatch_noise = get_noise(batch_size, noise_size)\n",
        "\t\t\t\t\n",
        "\t\t\t\tsess.run(g_opt, feed_dict = {input_real: batch_image, input_noise: batch_noise})\n",
        "\t\t\t\tsess.run(d_opt, feed_dict = {input_real: batch_image, input_noise: batch_noise})\n",
        "                        \n",
        "\t\t\t#显示图片\n",
        "\t\t\tprint('round :', i)\n",
        "\t\t\tprint('G loss: ', g_loss.eval({input_real: batch_image, input_noise: batch_noise}))\n",
        "\t\t\tprint('D loss: ', d_loss.eval({input_real: batch_image, input_noise: batch_noise}))\n",
        "\t\t\tprint('')\n",
        "\t\t\tif i % 5 == 0:\n",
        "\t\t\t\tshow_image(sess, input_noise, data_shape, epoch = i)\n",
        "\t\t\t\t\n",
        "with tf.Graph().as_default():\n",
        "    train(noise_size, [-1, 128, 128, 3], batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbccp1Ard_0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUzcLFp-eBjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoPpTA06dM_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}